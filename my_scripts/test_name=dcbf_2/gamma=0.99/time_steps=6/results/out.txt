summary_dir /afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=6
use_gpu True
save_model True
load_model False
random_seed 1754
buffer_size 1000000
max_episodes 200
max_episode_len 1464
mini_batch_size 300
actor_lr 0.0001
critic_lr 0.001
gamma 0.99
noise_var 0.0925
scaling True
state_dim 2
action_dim 1
action_bound [1.]
discretization_time 0.001
T_set_max_min [23.0, 26.0]
T_max_min [22.0, 23.0]
time_steps 6
actor_rnn 10
actor_l1 50
actor_l2 40
critic_rnn 10
critic_l1 50
critic_l2 20
tau 0.001
{'T_max_min': [22.0, 23.0],
 'T_set_max_min': [23.0, 26.0],
 'action_bound': array([1.], dtype=float32),
 'action_dim': 1,
 'actor_l1': 50,
 'actor_l2': 40,
 'actor_lr': 0.0001,
 'actor_rnn': 10,
 'buffer_size': 1000000,
 'critic_l1': 50,
 'critic_l2': 20,
 'critic_lr': 0.001,
 'critic_rnn': 10,
 'discretization_time': 0.001,
 'gamma': 0.99,
 'load_model': False,
 'max_episode_len': 1464,
 'max_episodes': 200,
 'mini_batch_size': 300,
 'noise_var': 0.0925,
 'random_seed': 1754,
 'save_model': True,
 'scaling': True,
 'state_dim': 2,
 'summary_dir': '/afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=6',
 'tau': 0.001,
 'time_steps': 6,
 'use_gpu': True}
starting the scaling
finished the scaling
[0.48155904 0.02820197] [ 24.00310551 -28.56439297]
initalizing the actor and critic func
loading the weights
Model: "actor_network"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
actor_input_state (InputLaye [(None, 6, 2)]            0         
_________________________________________________________________
conv1d (Conv1D)              (None, 5, 16)             80        
_________________________________________________________________
actor_rnn (GRU)              (None, 10)                840       
_________________________________________________________________
actor_dense_1 (Dense)        (None, 50)                550       
_________________________________________________________________
batch_normalization (BatchNo (None, 50)                200       
_________________________________________________________________
activation (Activation)      (None, 50)                0         
_________________________________________________________________
actor_dense_2 (Dense)        (None, 40)                2040      
_________________________________________________________________
batch_normalization_1 (Batch (None, 40)                160       
_________________________________________________________________
activation_1 (Activation)    (None, 40)                0         
_________________________________________________________________
actor_dense_3 (Dense)        (None, 1)                 41        
_________________________________________________________________
tf_op_layer_actions_scaling  [(None, 1)]               0         
=================================================================
Total params: 3,911
Trainable params: 3,731
Non-trainable params: 180
_________________________________________________________________
None
Model: "critic_network"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
critic_input_state (InputLayer) [(None, 6, 2)]       0                                            
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 5, 16)        80          critic_input_state[0][0]         
__________________________________________________________________________________________________
gru (GRU)                       (None, 10)           840         conv1d_2[0][0]                   
__________________________________________________________________________________________________
critic_dense_1 (Dense)          (None, 50)           550         gru[0][0]                        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 50)           200         critic_dense_1[0][0]             
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
critic_input_action (InputLayer [(None, 1)]          0                                            
__________________________________________________________________________________________________
critic_dense_2_state (Dense)    (None, 20)           1020        activation_4[0][0]               
__________________________________________________________________________________________________
critic_dense_2_action (Dense)   (None, 20)           40          critic_input_action[0][0]        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 40)           0           critic_dense_2_state[0][0]       
                                                                 critic_dense_2_action[0][0]      
__________________________________________________________________________________________________
critic_dense_3_state (Dense)    (None, 20)           820         concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20)           80          critic_dense_3_state[0][0]       
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20)           0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
Q_val (Dense)                   (None, 1)            21          activation_5[0][0]               
==================================================================================================
Total params: 3,651
Trainable params: 3,511
Non-trainable params: 140
__________________________________________________________________________________________________
None
starting the simulation
running - train_rnn_cbf
| Reward: 11285.2474 | Episode: 0 | Qmax: 9.8691
| Reward: 11285.2476 | Episode: 1 | Qmax: 19.5763
| Reward: 11285.2476 | Episode: 2 | Qmax: 30.2456
| Reward: 11285.2476 | Episode: 3 | Qmax: 42.8835
| Reward: 11285.2476 | Episode: 4 | Qmax: 55.0193
| Reward: 11285.2475 | Episode: 5 | Qmax: 66.1482
| Reward: 11285.2475 | Episode: 6 | Qmax: 76.4969
| Reward: 11285.2474 | Episode: 7 | Qmax: 86.1519
| Reward: 11285.2474 | Episode: 8 | Qmax: 94.9321
| Reward: 11285.2475 | Episode: 9 | Qmax: 102.6319
| Reward: 11285.2474 | Episode: 10 | Qmax: 109.3004
| Reward: 11285.2476 | Episode: 11 | Qmax: 115.9310
| Reward: 11285.2473 | Episode: 12 | Qmax: 122.2200
| Reward: 11285.2473 | Episode: 13 | Qmax: 128.6155
| Reward: 11285.2474 | Episode: 14 | Qmax: 135.3435
| Reward: 11285.2473 | Episode: 15 | Qmax: 142.2867
| Reward: 11285.2475 | Episode: 16 | Qmax: 149.4592
| Reward: 11285.2474 | Episode: 17 | Qmax: 157.2710
| Reward: 11285.2475 | Episode: 18 | Qmax: 165.3730
| Reward: 11285.2475 | Episode: 19 | Qmax: 173.5291
| Reward: 11285.2474 | Episode: 20 | Qmax: 181.7342
| Reward: 11285.2474 | Episode: 21 | Qmax: 189.7191
| Reward: 11285.2475 | Episode: 22 | Qmax: 197.7481
| Reward: 11285.2474 | Episode: 23 | Qmax: 205.2655
| Reward: 11285.2475 | Episode: 24 | Qmax: 212.4612
| Reward: 11285.2473 | Episode: 25 | Qmax: 219.3355
| Reward: 11285.2473 | Episode: 26 | Qmax: 225.5808
| Reward: 11285.2474 | Episode: 27 | Qmax: 231.6118
| Reward: 11285.2474 | Episode: 28 | Qmax: 237.4856
| Reward: 11285.2475 | Episode: 29 | Qmax: 243.0702
| Reward: 11285.2474 | Episode: 30 | Qmax: 248.7983
| Reward: 11285.2475 | Episode: 31 | Qmax: 254.2377
| Reward: 11285.2474 | Episode: 32 | Qmax: 259.6791
| Reward: 11285.2475 | Episode: 33 | Qmax: 265.0353
| Reward: 11285.2473 | Episode: 34 | Qmax: 270.2518
| Reward: 11285.2475 | Episode: 35 | Qmax: 275.6979
| Reward: 11285.2473 | Episode: 36 | Qmax: 280.7960
| Reward: 11285.2475 | Episode: 37 | Qmax: 285.7728
| Reward: 11285.2474 | Episode: 38 | Qmax: 290.6374
| Reward: 11285.2473 | Episode: 39 | Qmax: 295.4109
| Reward: 11285.2475 | Episode: 40 | Qmax: 299.8741
| Reward: 11285.2474 | Episode: 41 | Qmax: 304.0590
| Reward: 11285.2474 | Episode: 42 | Qmax: 308.0575
| Reward: 11285.2474 | Episode: 43 | Qmax: 311.9067
| Reward: 11285.2475 | Episode: 44 | Qmax: 315.9629
| Reward: 11285.2473 | Episode: 45 | Qmax: 320.2327
| Reward: 11285.2475 | Episode: 46 | Qmax: 325.1001
| Reward: 11285.2474 | Episode: 47 | Qmax: 327.5909
| Reward: 11285.2474 | Episode: 48 | Qmax: 328.3933
| Reward: 11285.2474 | Episode: 49 | Qmax: 329.2791
| Reward: 11285.2475 | Episode: 50 | Qmax: 329.9623
| Reward: 11285.2475 | Episode: 51 | Qmax: 332.4607
| Reward: 11285.2473 | Episode: 52 | Qmax: 335.8556
| Reward: 11285.2474 | Episode: 53 | Qmax: 339.9831
| Reward: 11285.2474 | Episode: 54 | Qmax: 345.0161
| Reward: 11285.2474 | Episode: 55 | Qmax: 351.0617
| Reward: 11285.2473 | Episode: 56 | Qmax: 358.3007
| Reward: 11285.2472 | Episode: 57 | Qmax: 365.7801
| Reward: 11285.2473 | Episode: 58 | Qmax: 373.6882
| Reward: 11285.2474 | Episode: 59 | Qmax: 380.2678
| Reward: 11285.2474 | Episode: 60 | Qmax: 383.4740
| Reward: 11285.2474 | Episode: 61 | Qmax: 382.8486
| Reward: 11285.2475 | Episode: 62 | Qmax: 379.1949
| Reward: 11285.2473 | Episode: 63 | Qmax: 372.0686
| Reward: 11285.2474 | Episode: 64 | Qmax: 361.9900
| Reward: 11285.2475 | Episode: 65 | Qmax: 353.0416
| Reward: 11285.2475 | Episode: 66 | Qmax: 345.0509
| Reward: 11285.2474 | Episode: 67 | Qmax: 339.1008
| Reward: 11285.2473 | Episode: 68 | Qmax: 333.4587
| Reward: 11285.2476 | Episode: 69 | Qmax: 329.6634
| Reward: 11285.2473 | Episode: 70 | Qmax: 326.6797
| Reward: 11285.2475 | Episode: 71 | Qmax: 325.7921
| Reward: 11285.2475 | Episode: 72 | Qmax: 326.9103
| Reward: 11285.2474 | Episode: 73 | Qmax: 329.0430
| Reward: 11285.2475 | Episode: 74 | Qmax: 329.3409
| Reward: 11285.2473 | Episode: 75 | Qmax: 324.5631
| Reward: 11285.2475 | Episode: 76 | Qmax: 322.2788
| Reward: 11285.2475 | Episode: 77 | Qmax: 321.0554
| Reward: 11285.2475 | Episode: 78 | Qmax: 320.9866
| Reward: 11285.2473 | Episode: 79 | Qmax: 321.9543
| Reward: 11285.2475 | Episode: 80 | Qmax: 325.1134
| Reward: 11285.2475 | Episode: 81 | Qmax: 329.3044
| Reward: 11285.2475 | Episode: 82 | Qmax: 333.4577
| Reward: 11285.2474 | Episode: 83 | Qmax: 339.0722
| Reward: 11285.2475 | Episode: 84 | Qmax: 344.1924
| Reward: 11285.2475 | Episode: 85 | Qmax: 351.0070
| Reward: 11285.2476 | Episode: 86 | Qmax: 358.2490
| Reward: 11285.2474 | Episode: 87 | Qmax: 368.1153
| Reward: 11285.2475 | Episode: 88 | Qmax: 380.8853
| Reward: 11285.2473 | Episode: 89 | Qmax: 395.3855
| Reward: 11285.2473 | Episode: 90 | Qmax: 413.5284
| Reward: 11285.2473 | Episode: 91 | Qmax: 435.6006
| Reward: 11285.2475 | Episode: 92 | Qmax: 461.3922
| Reward: 11285.2473 | Episode: 93 | Qmax: 488.7538
| Reward: 11285.2474 | Episode: 94 | Qmax: 517.0627
| Reward: 11285.2474 | Episode: 95 | Qmax: 543.1916
| Reward: 11285.2476 | Episode: 96 | Qmax: 575.7571
| Reward: 11285.2475 | Episode: 97 | Qmax: 617.4797
| Reward: 11285.2475 | Episode: 98 | Qmax: 662.6346
| Reward: 11285.2476 | Episode: 99 | Qmax: 706.3345
| Reward: 11285.2474 | Episode: 100 | Qmax: 741.5281
| Reward: 11285.2476 | Episode: 101 | Qmax: 767.9024
| Reward: 11285.2476 | Episode: 102 | Qmax: 792.1211
| Reward: 11285.2473 | Episode: 103 | Qmax: 817.0559
| Reward: 11285.2474 | Episode: 104 | Qmax: 848.0967
| Reward: 11285.2476 | Episode: 105 | Qmax: 890.1047
| Reward: 11285.2475 | Episode: 106 | Qmax: 948.0639
| Reward: 11285.2473 | Episode: 107 | Qmax: 1010.5525
| Reward: 11285.2475 | Episode: 108 | Qmax: 1057.6695
| Reward: 11285.2474 | Episode: 109 | Qmax: 1112.6186
| Reward: 11285.2474 | Episode: 110 | Qmax: 1170.7040
| Reward: 11285.2473 | Episode: 111 | Qmax: 1229.9204
| Reward: 11285.2473 | Episode: 112 | Qmax: 1267.2734
| Reward: 11285.2474 | Episode: 113 | Qmax: 1311.4239
| Reward: 11285.2476 | Episode: 114 | Qmax: 1339.4646
| Reward: 11285.2474 | Episode: 115 | Qmax: 1379.1724
| Reward: 11285.2473 | Episode: 116 | Qmax: 1420.7718
| Reward: 11285.2475 | Episode: 117 | Qmax: 1462.5838
| Reward: 11285.2473 | Episode: 118 | Qmax: 1536.4514
| Reward: 11285.2474 | Episode: 119 | Qmax: 1625.7074
| Reward: 11285.2473 | Episode: 120 | Qmax: 1748.1024
| Reward: 11285.2473 | Episode: 121 | Qmax: 1895.6846
| Reward: 11285.2472 | Episode: 122 | Qmax: 1990.4396
| Reward: 11285.2473 | Episode: 123 | Qmax: 2106.9867
| Reward: 11285.2473 | Episode: 124 | Qmax: 2185.6985
| Reward: 11285.2474 | Episode: 125 | Qmax: 2254.5958
| Reward: 11285.2475 | Episode: 126 | Qmax: 2330.7412
| Reward: 11285.2475 | Episode: 127 | Qmax: 2431.6171
| Reward: 11285.2474 | Episode: 128 | Qmax: 2529.1886
| Reward: 11285.2474 | Episode: 129 | Qmax: 2688.5255
| Reward: 11285.2474 | Episode: 130 | Qmax: 2885.2864
| Reward: 11285.2473 | Episode: 131 | Qmax: 3114.8846
| Reward: 11285.2476 | Episode: 132 | Qmax: 3352.9716
| Reward: 11285.2475 | Episode: 133 | Qmax: 3629.1474
| Reward: 11285.2475 | Episode: 134 | Qmax: 3900.9869
| Reward: 11285.2475 | Episode: 135 | Qmax: 4179.8594
| Reward: 11285.2474 | Episode: 136 | Qmax: 4378.2377
| Reward: 11285.2474 | Episode: 137 | Qmax: 4372.1417
| Reward: 11285.2473 | Episode: 138 | Qmax: 4334.3223
| Reward: 11285.2475 | Episode: 139 | Qmax: 4290.5517
| Reward: 11285.2475 | Episode: 140 | Qmax: 4302.7502
| Reward: 11285.2473 | Episode: 141 | Qmax: 4300.3895
| Reward: 11285.2475 | Episode: 142 | Qmax: 4267.7594
| Reward: 11285.2475 | Episode: 143 | Qmax: 4196.1523
| Reward: 11285.2475 | Episode: 144 | Qmax: 4124.4605
| Reward: 11285.2475 | Episode: 145 | Qmax: 4029.6501
| Reward: 11285.2474 | Episode: 146 | Qmax: 3977.2265
| Reward: 11285.2475 | Episode: 147 | Qmax: 3932.8191
| Reward: 11285.2474 | Episode: 148 | Qmax: 3920.2489
| Reward: 11285.2474 | Episode: 149 | Qmax: 3949.9567
| Reward: 11285.2475 | Episode: 150 | Qmax: 4018.0918
| Reward: 11285.2473 | Episode: 151 | Qmax: 4159.9543
| Reward: 11285.2475 | Episode: 152 | Qmax: 4287.9728
| Reward: 11285.2473 | Episode: 153 | Qmax: 4545.4656
| Reward: 11285.2475 | Episode: 154 | Qmax: 4749.4534
| Reward: 11285.2474 | Episode: 155 | Qmax: 5189.8035
| Reward: 11285.2476 | Episode: 156 | Qmax: 5794.6496
| Reward: 11285.2475 | Episode: 157 | Qmax: 6846.2759
| Reward: 11285.2474 | Episode: 158 | Qmax: 8361.3282
| Reward: 11285.2474 | Episode: 159 | Qmax: 10270.2610
| Reward: 11285.2475 | Episode: 160 | Qmax: 13497.6418
| Reward: 11285.2475 | Episode: 161 | Qmax: 18980.9055
| Reward: 11285.2473 | Episode: 162 | Qmax: 27095.0218
| Reward: 11285.2475 | Episode: 163 | Qmax: 34296.7090
| Reward: 11285.2474 | Episode: 164 | Qmax: 47989.7981
| Reward: 11285.2474 | Episode: 165 | Qmax: 60982.1249
| Reward: 11285.2475 | Episode: 166 | Qmax: 77947.9979
| Reward: 11285.2474 | Episode: 167 | Qmax: 101334.4281
| Reward: 11285.2474 | Episode: 168 | Qmax: 132531.1450
| Reward: 11285.2473 | Episode: 169 | Qmax: 172828.5395
| Reward: 11285.2475 | Episode: 170 | Qmax: 224239.0071
| Reward: 11285.2474 | Episode: 171 | Qmax: 286994.3944
| Reward: 11285.2475 | Episode: 172 | Qmax: 367960.4721
| Reward: 11285.2474 | Episode: 173 | Qmax: 465491.2695
| Reward: 11285.2476 | Episode: 174 | Qmax: 585048.4766
| Reward: 11285.2474 | Episode: 175 | Qmax: 732845.4274
| Reward: 11285.2474 | Episode: 176 | Qmax: 912696.5178
| Reward: 11285.2474 | Episode: 177 | Qmax: 1138436.3082
| Reward: 11285.2474 | Episode: 178 | Qmax: 1419143.5173
| Reward: 11285.2474 | Episode: 179 | Qmax: 1764983.5851
| Reward: 11285.2473 | Episode: 180 | Qmax: 2184717.9462
| Reward: 11285.2476 | Episode: 181 | Qmax: 2716536.2294
| Reward: 11285.2475 | Episode: 182 | Qmax: 3368097.1991
| Reward: 11285.2475 | Episode: 183 | Qmax: 4179980.0753
| Reward: 11285.2475 | Episode: 184 | Qmax: 5177296.1739
| Reward: 11285.2475 | Episode: 185 | Qmax: 6387828.3567
| Reward: 11285.2474 | Episode: 186 | Qmax: 7850907.5340
| Reward: 11285.2475 | Episode: 187 | Qmax: 9634115.8471
| Reward: 11285.2476 | Episode: 188 | Qmax: 11732557.5329
| Reward: 11285.2475 | Episode: 189 | Qmax: 14248355.5569
| Reward: 11285.2473 | Episode: 190 | Qmax: 17219706.2572
| Reward: 11285.2476 | Episode: 191 | Qmax: 20685267.2977
| Reward: 11285.2473 | Episode: 192 | Qmax: 24695697.3827
| Reward: 11285.2475 | Episode: 193 | Qmax: 29408383.1495
| Reward: 11285.2474 | Episode: 194 | Qmax: 34934923.5857
| Reward: 11285.2475 | Episode: 195 | Qmax: 41315493.9698
| Reward: 11285.2475 | Episode: 196 | Qmax: 48751770.1125
| Reward: 11285.2474 | Episode: 197 | Qmax: 57174301.9314
| Reward: 11285.2474 | Episode: 198 | Qmax: 66705068.0823
| Reward: 11285.2474 | Episode: 199 | Qmax: 77678774.9410
saving weights
Plotting an new testing environment
