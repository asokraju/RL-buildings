summary_dir /afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=10
use_gpu True
save_model True
load_model False
random_seed 1754
buffer_size 1000000
max_episodes 200
max_episode_len 1464
mini_batch_size 300
actor_lr 0.0001
critic_lr 0.001
gamma 0.99
noise_var 0.0925
scaling True
state_dim 2
action_dim 1
action_bound [1.]
discretization_time 0.001
T_set_max_min [23.0, 26.0]
T_max_min [22.0, 25.0]
time_steps 10
actor_rnn 10
actor_l1 50
actor_l2 40
critic_rnn 10
critic_l1 50
critic_l2 20
tau 0.001
{'T_max_min': [22.0, 25.0],
 'T_set_max_min': [23.0, 26.0],
 'action_bound': array([1.], dtype=float32),
 'action_dim': 1,
 'actor_l1': 50,
 'actor_l2': 40,
 'actor_lr': 0.0001,
 'actor_rnn': 10,
 'buffer_size': 1000000,
 'critic_l1': 50,
 'critic_l2': 20,
 'critic_lr': 0.001,
 'critic_rnn': 10,
 'discretization_time': 0.001,
 'gamma': 0.99,
 'load_model': False,
 'max_episode_len': 1464,
 'max_episodes': 200,
 'mini_batch_size': 300,
 'noise_var': 0.0925,
 'random_seed': 1754,
 'save_model': True,
 'scaling': True,
 'state_dim': 2,
 'summary_dir': '/afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=10',
 'tau': 0.001,
 'time_steps': 10,
 'use_gpu': True}
starting the scaling
finished the scaling
[0.48211808 0.02819109] [ 24.00307911 -28.56464464]
initalizing the actor and critic func
loading the weights
Model: "actor_network"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
actor_input_state (InputLaye [(None, 10, 2)]           0         
_________________________________________________________________
conv1d (Conv1D)              (None, 9, 16)             80        
_________________________________________________________________
actor_rnn (GRU)              (None, 10)                840       
_________________________________________________________________
actor_dense_1 (Dense)        (None, 50)                550       
_________________________________________________________________
batch_normalization (BatchNo (None, 50)                200       
_________________________________________________________________
activation (Activation)      (None, 50)                0         
_________________________________________________________________
actor_dense_2 (Dense)        (None, 40)                2040      
_________________________________________________________________
batch_normalization_1 (Batch (None, 40)                160       
_________________________________________________________________
activation_1 (Activation)    (None, 40)                0         
_________________________________________________________________
actor_dense_3 (Dense)        (None, 1)                 41        
_________________________________________________________________
tf_op_layer_actions_scaling  [(None, 1)]               0         
=================================================================
Total params: 3,911
Trainable params: 3,731
Non-trainable params: 180
_________________________________________________________________
None
Model: "critic_network"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
critic_input_state (InputLayer) [(None, 10, 2)]      0                                            
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 9, 16)        80          critic_input_state[0][0]         
__________________________________________________________________________________________________
gru (GRU)                       (None, 10)           840         conv1d_2[0][0]                   
__________________________________________________________________________________________________
critic_dense_1 (Dense)          (None, 50)           550         gru[0][0]                        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 50)           200         critic_dense_1[0][0]             
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
critic_input_action (InputLayer [(None, 1)]          0                                            
__________________________________________________________________________________________________
critic_dense_2_state (Dense)    (None, 20)           1020        activation_4[0][0]               
__________________________________________________________________________________________________
critic_dense_2_action (Dense)   (None, 20)           40          critic_input_action[0][0]        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 40)           0           critic_dense_2_state[0][0]       
                                                                 critic_dense_2_action[0][0]      
__________________________________________________________________________________________________
critic_dense_3_state (Dense)    (None, 20)           820         concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20)           80          critic_dense_3_state[0][0]       
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20)           0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
Q_val (Dense)                   (None, 1)            21          activation_5[0][0]               
==================================================================================================
Total params: 3,651
Trainable params: 3,511
Non-trainable params: 140
__________________________________________________________________________________________________
None
starting the simulation
running - train_rnn_cbf
| Reward: 10040.5065 | Episode: 0 | Qmax: 9.4962
| Reward: 9832.5125 | Episode: 1 | Qmax: 19.3342
| Reward: 9831.9781 | Episode: 2 | Qmax: 31.5820
| Reward: 10863.5602 | Episode: 3 | Qmax: 49.8712
| Reward: 11222.0976 | Episode: 4 | Qmax: 75.3731
| Reward: 11221.5526 | Episode: 5 | Qmax: 105.0706
| Reward: 11221.3414 | Episode: 6 | Qmax: 132.2766
| Reward: 11221.4116 | Episode: 7 | Qmax: 154.4103
| Reward: 11221.2329 | Episode: 8 | Qmax: 174.8402
| Reward: 11221.4919 | Episode: 9 | Qmax: 196.0288
| Reward: 11222.0901 | Episode: 10 | Qmax: 215.2392
| Reward: 11221.4510 | Episode: 11 | Qmax: 231.4556
| Reward: 11221.8453 | Episode: 12 | Qmax: 246.3015
| Reward: 11221.2750 | Episode: 13 | Qmax: 259.7631
| Reward: 11221.5929 | Episode: 14 | Qmax: 273.6279
| Reward: 11221.7292 | Episode: 15 | Qmax: 290.1597
| Reward: 11221.2360 | Episode: 16 | Qmax: 306.9742
| Reward: 11221.6961 | Episode: 17 | Qmax: 321.5710
| Reward: 11220.8632 | Episode: 18 | Qmax: 336.7636
| Reward: 11221.5693 | Episode: 19 | Qmax: 352.8685
| Reward: 11221.2256 | Episode: 20 | Qmax: 368.7948
| Reward: 11221.8627 | Episode: 21 | Qmax: 383.6866
| Reward: 11221.7879 | Episode: 22 | Qmax: 402.4365
| Reward: 11221.8510 | Episode: 23 | Qmax: 427.6551
| Reward: 11221.7714 | Episode: 24 | Qmax: 457.2150
| Reward: 11221.4128 | Episode: 25 | Qmax: 492.3561
| Reward: 11221.8483 | Episode: 26 | Qmax: 529.2765
| Reward: 11221.9447 | Episode: 27 | Qmax: 571.7567
| Reward: 11221.2907 | Episode: 28 | Qmax: 614.3114
| Reward: 11221.6978 | Episode: 29 | Qmax: 654.2894
| Reward: 11221.2652 | Episode: 30 | Qmax: 687.7673
| Reward: 11221.8866 | Episode: 31 | Qmax: 717.8211
| Reward: 11221.5007 | Episode: 32 | Qmax: 746.1942
| Reward: 11221.8130 | Episode: 33 | Qmax: 775.1879
| Reward: 11221.6848 | Episode: 34 | Qmax: 806.0463
| Reward: 11221.4292 | Episode: 35 | Qmax: 835.8668
| Reward: 11221.3074 | Episode: 36 | Qmax: 862.6432
| Reward: 11221.1039 | Episode: 37 | Qmax: 887.5445
| Reward: 11221.4008 | Episode: 38 | Qmax: 911.8018
| Reward: 11221.2038 | Episode: 39 | Qmax: 930.9173
| Reward: 11221.6984 | Episode: 40 | Qmax: 955.9158
| Reward: 11221.1548 | Episode: 41 | Qmax: 986.0154
| Reward: 11221.5530 | Episode: 42 | Qmax: 1018.0562
| Reward: 11221.5595 | Episode: 43 | Qmax: 1051.4884
| Reward: 11221.3000 | Episode: 44 | Qmax: 1091.3374
| Reward: 11221.5776 | Episode: 45 | Qmax: 1125.2571
| Reward: 11221.4224 | Episode: 46 | Qmax: 1156.2371
| Reward: 11221.2768 | Episode: 47 | Qmax: 1176.5450
| Reward: 11221.8764 | Episode: 48 | Qmax: 1181.3201
| Reward: 11221.7613 | Episode: 49 | Qmax: 1174.9580
| Reward: 11221.7365 | Episode: 50 | Qmax: 1158.6369
| Reward: 11221.9638 | Episode: 51 | Qmax: 1135.4421
| Reward: 11221.8850 | Episode: 52 | Qmax: 1105.6150
| Reward: 11221.7883 | Episode: 53 | Qmax: 1071.4667
| Reward: 11221.8216 | Episode: 54 | Qmax: 1032.8319
| Reward: 11221.1454 | Episode: 55 | Qmax: 992.1705
| Reward: 11221.4460 | Episode: 56 | Qmax: 949.7355
| Reward: 11220.5762 | Episode: 57 | Qmax: 906.6579
| Reward: 11221.5504 | Episode: 58 | Qmax: 865.2401
| Reward: 11221.2646 | Episode: 59 | Qmax: 822.9163
| Reward: 11221.4958 | Episode: 60 | Qmax: 783.7238
| Reward: 11221.6961 | Episode: 61 | Qmax: 749.4677
| Reward: 11221.3710 | Episode: 62 | Qmax: 720.2679
| Reward: 11221.9907 | Episode: 63 | Qmax: 697.5934
| Reward: 11221.3336 | Episode: 64 | Qmax: 679.7483
| Reward: 11221.5641 | Episode: 65 | Qmax: 666.6055
| Reward: 11221.5279 | Episode: 66 | Qmax: 657.8314
| Reward: 11221.0542 | Episode: 67 | Qmax: 652.1038
| Reward: 11222.0077 | Episode: 68 | Qmax: 645.6777
| Reward: 11221.4604 | Episode: 69 | Qmax: 640.4008
| Reward: 11221.7902 | Episode: 70 | Qmax: 636.1057
| Reward: 11221.5436 | Episode: 71 | Qmax: 632.7066
| Reward: 11221.7386 | Episode: 72 | Qmax: 632.2954
| Reward: 11221.4858 | Episode: 73 | Qmax: 635.0853
| Reward: 11221.7975 | Episode: 74 | Qmax: 637.6756
| Reward: 11221.4813 | Episode: 75 | Qmax: 642.8412
| Reward: 11221.1025 | Episode: 76 | Qmax: 648.8952
| Reward: 11221.5457 | Episode: 77 | Qmax: 657.0269
| Reward: 11220.8372 | Episode: 78 | Qmax: 664.5775
| Reward: 11221.2497 | Episode: 79 | Qmax: 671.9351
| Reward: 11221.8820 | Episode: 80 | Qmax: 680.1179
| Reward: 11220.8519 | Episode: 81 | Qmax: 686.5855
| Reward: 11221.3894 | Episode: 82 | Qmax: 694.3999
| Reward: 11221.8281 | Episode: 83 | Qmax: 702.1733
| Reward: 11221.9215 | Episode: 84 | Qmax: 709.9197
| Reward: 11221.8175 | Episode: 85 | Qmax: 719.5587
| Reward: 11221.3495 | Episode: 86 | Qmax: 728.0892
| Reward: 11221.5351 | Episode: 87 | Qmax: 730.7569
| Reward: 11221.2786 | Episode: 88 | Qmax: 733.1052
| Reward: 11221.8390 | Episode: 89 | Qmax: 737.1375
| Reward: 11221.8708 | Episode: 90 | Qmax: 739.8525
| Reward: 11221.1190 | Episode: 91 | Qmax: 743.4167
| Reward: 11221.4980 | Episode: 92 | Qmax: 747.0204
| Reward: 11221.7211 | Episode: 93 | Qmax: 751.5983
| Reward: 11221.2254 | Episode: 94 | Qmax: 756.3045
| Reward: 11221.7259 | Episode: 95 | Qmax: 760.6964
| Reward: 11221.6388 | Episode: 96 | Qmax: 765.3097
| Reward: 11221.6050 | Episode: 97 | Qmax: 771.5765
| Reward: 11221.6476 | Episode: 98 | Qmax: 779.9121
| Reward: 11221.5245 | Episode: 99 | Qmax: 791.4774
| Reward: 11221.8529 | Episode: 100 | Qmax: 804.9039
| Reward: 11221.5822 | Episode: 101 | Qmax: 824.1848
| Reward: 11221.3114 | Episode: 102 | Qmax: 848.5931
| Reward: 11221.6551 | Episode: 103 | Qmax: 878.7182
| Reward: 11221.6984 | Episode: 104 | Qmax: 909.8047
| Reward: 11221.5552 | Episode: 105 | Qmax: 939.9727
| Reward: 11221.8961 | Episode: 106 | Qmax: 971.9834
| Reward: 11221.6349 | Episode: 107 | Qmax: 995.7696
| Reward: 11221.6923 | Episode: 108 | Qmax: 1019.7562
| Reward: 11221.3655 | Episode: 109 | Qmax: 1048.1445
| Reward: 11221.4509 | Episode: 110 | Qmax: 1076.9286
| Reward: 11221.4903 | Episode: 111 | Qmax: 1105.4549
| Reward: 11221.5254 | Episode: 112 | Qmax: 1126.8300
| Reward: 11221.5072 | Episode: 113 | Qmax: 1145.1373
| Reward: 11221.5559 | Episode: 114 | Qmax: 1167.2656
| Reward: 11221.4927 | Episode: 115 | Qmax: 1180.8867
| Reward: 11221.1263 | Episode: 116 | Qmax: 1195.3258
| Reward: 11221.6761 | Episode: 117 | Qmax: 1205.6246
| Reward: 11221.2747 | Episode: 118 | Qmax: 1209.4604
| Reward: 11221.3359 | Episode: 119 | Qmax: 1212.2133
| Reward: 11221.3533 | Episode: 120 | Qmax: 1214.8398
| Reward: 11221.2642 | Episode: 121 | Qmax: 1215.0069
| Reward: 11221.7802 | Episode: 122 | Qmax: 1214.5993
| Reward: 11221.6974 | Episode: 123 | Qmax: 1213.7203
| Reward: 11221.8570 | Episode: 124 | Qmax: 1215.9993
| Reward: 11221.2847 | Episode: 125 | Qmax: 1223.0668
| Reward: 11221.7223 | Episode: 126 | Qmax: 1236.8817
| Reward: 11220.8500 | Episode: 127 | Qmax: 1244.0460
| Reward: 11221.4752 | Episode: 128 | Qmax: 1255.6934
| Reward: 11221.5036 | Episode: 129 | Qmax: 1267.1693
| Reward: 11221.0740 | Episode: 130 | Qmax: 1273.4189
| Reward: 11221.4802 | Episode: 131 | Qmax: 1281.6504
| Reward: 11221.9683 | Episode: 132 | Qmax: 1289.6245
| Reward: 11221.2446 | Episode: 133 | Qmax: 1295.9126
| Reward: 11221.3977 | Episode: 134 | Qmax: 1306.8492
| Reward: 11221.6383 | Episode: 135 | Qmax: 1322.9550
| Reward: 11221.6426 | Episode: 136 | Qmax: 1335.0818
| Reward: 11221.3610 | Episode: 137 | Qmax: 1350.6083
| Reward: 11221.3982 | Episode: 138 | Qmax: 1364.8851
| Reward: 11221.5991 | Episode: 139 | Qmax: 1395.5599
| Reward: 11221.3132 | Episode: 140 | Qmax: 1410.1369
| Reward: 11221.3559 | Episode: 141 | Qmax: 1434.1861
| Reward: 11221.2721 | Episode: 142 | Qmax: 1450.3134
| Reward: 11221.9569 | Episode: 143 | Qmax: 1463.5945
| Reward: 11220.9359 | Episode: 144 | Qmax: 1488.0052
| Reward: 11221.6111 | Episode: 145 | Qmax: 1503.4695
| Reward: 11221.4512 | Episode: 146 | Qmax: 1505.9096
| Reward: 11221.5509 | Episode: 147 | Qmax: 1514.7179
| Reward: 11221.4869 | Episode: 148 | Qmax: 1518.5760
| Reward: 11221.5777 | Episode: 149 | Qmax: 1519.4710
| Reward: 11221.2954 | Episode: 150 | Qmax: 1522.4660
| Reward: 11221.5802 | Episode: 151 | Qmax: 1539.8206
| Reward: 11221.3867 | Episode: 152 | Qmax: 1535.3896
| Reward: 11221.3375 | Episode: 153 | Qmax: 1536.1085
| Reward: 11221.2942 | Episode: 154 | Qmax: 1545.6512
| Reward: 11221.4616 | Episode: 155 | Qmax: 1547.8677
| Reward: 11221.7013 | Episode: 156 | Qmax: 1551.3539
| Reward: 11221.3637 | Episode: 157 | Qmax: 1562.2464
| Reward: 11221.7782 | Episode: 158 | Qmax: 1566.6433
| Reward: 11221.9828 | Episode: 159 | Qmax: 1576.1702
| Reward: 11221.2281 | Episode: 160 | Qmax: 1588.4795
| Reward: 11221.3900 | Episode: 161 | Qmax: 1585.8448
| Reward: 11221.6855 | Episode: 162 | Qmax: 1588.6235
| Reward: 11221.6598 | Episode: 163 | Qmax: 1587.5345
| Reward: 11221.2066 | Episode: 164 | Qmax: 1589.8175
| Reward: 11221.7636 | Episode: 165 | Qmax: 1595.4899
| Reward: 11221.3934 | Episode: 166 | Qmax: 1592.2406
| Reward: 11221.5509 | Episode: 167 | Qmax: 1591.7929
| Reward: 11222.0653 | Episode: 168 | Qmax: 1626.9736
| Reward: 11221.6965 | Episode: 169 | Qmax: 1694.7343
| Reward: 11221.3084 | Episode: 170 | Qmax: 1760.6547
| Reward: 11221.0589 | Episode: 171 | Qmax: 1815.5770
| Reward: 11221.3876 | Episode: 172 | Qmax: 1876.9383
| Reward: 11221.2749 | Episode: 173 | Qmax: 1930.5198
| Reward: 11221.6144 | Episode: 174 | Qmax: 1988.8580
| Reward: 11221.3980 | Episode: 175 | Qmax: 2050.4774
| Reward: 11221.6604 | Episode: 176 | Qmax: 2118.4031
| Reward: 11221.8414 | Episode: 177 | Qmax: 2168.7596
| Reward: 11221.7751 | Episode: 178 | Qmax: 2184.4792
| Reward: 11221.5793 | Episode: 179 | Qmax: 2192.6069
| Reward: 11221.0906 | Episode: 180 | Qmax: 2193.8057
| Reward: 11221.2351 | Episode: 181 | Qmax: 2199.6194
| Reward: 11221.3954 | Episode: 182 | Qmax: 2158.0574
| Reward: 11221.0242 | Episode: 183 | Qmax: 2128.2411
| Reward: 11221.7895 | Episode: 184 | Qmax: 2121.1965
| Reward: 11221.0302 | Episode: 185 | Qmax: 2125.3757
| Reward: 11221.3963 | Episode: 186 | Qmax: 2139.9835
| Reward: 11221.3387 | Episode: 187 | Qmax: 2160.8045
| Reward: 11221.6801 | Episode: 188 | Qmax: 2191.7776
| Reward: 11221.5510 | Episode: 189 | Qmax: 2216.4309
| Reward: 11221.2197 | Episode: 190 | Qmax: 2242.5402
| Reward: 11221.3992 | Episode: 191 | Qmax: 2269.3472
| Reward: 11221.7818 | Episode: 192 | Qmax: 2294.2882
| Reward: 11221.8159 | Episode: 193 | Qmax: 2318.4828
| Reward: 11221.6872 | Episode: 194 | Qmax: 2356.9943
| Reward: 11221.2580 | Episode: 195 | Qmax: 2401.2907
| Reward: 11221.4785 | Episode: 196 | Qmax: 2449.6280
| Reward: 11221.2780 | Episode: 197 | Qmax: 2489.8871
| Reward: 11221.6734 | Episode: 198 | Qmax: 2531.2403
| Reward: 11221.8919 | Episode: 199 | Qmax: 2574.8299
saving weights
Plotting an new testing environment
