summary_dir /afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=10
use_gpu True
save_model True
load_model False
random_seed 1754
buffer_size 1000000
max_episodes 200
max_episode_len 1464
mini_batch_size 300
actor_lr 0.0001
critic_lr 0.001
gamma 0.99
noise_var 0.0925
scaling True
state_dim 2
action_dim 1
action_bound [1.]
discretization_time 0.001
T_set_max_min [23.0, 26.0]
T_max_min [22.0, 23.0]
time_steps 10
actor_rnn 10
actor_l1 50
actor_l2 40
critic_rnn 10
critic_l1 50
critic_l2 20
tau 0.001
{'T_max_min': [22.0, 23.0],
 'T_set_max_min': [23.0, 26.0],
 'action_bound': array([1.], dtype=float32),
 'action_dim': 1,
 'actor_l1': 50,
 'actor_l2': 40,
 'actor_lr': 0.0001,
 'actor_rnn': 10,
 'buffer_size': 1000000,
 'critic_l1': 50,
 'critic_l2': 20,
 'critic_lr': 0.001,
 'critic_rnn': 10,
 'discretization_time': 0.001,
 'gamma': 0.99,
 'load_model': False,
 'max_episode_len': 1464,
 'max_episodes': 200,
 'mini_batch_size': 300,
 'noise_var': 0.0925,
 'random_seed': 1754,
 'save_model': True,
 'scaling': True,
 'state_dim': 2,
 'summary_dir': '/afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=10',
 'tau': 0.001,
 'time_steps': 10,
 'use_gpu': True}
starting the scaling
finished the scaling
[0.4800584  0.02821813] [ 24.00293878 -28.56506303]
initalizing the actor and critic func
loading the weights
Model: "actor_network"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
actor_input_state (InputLaye [(None, 10, 2)]           0         
_________________________________________________________________
conv1d (Conv1D)              (None, 9, 16)             80        
_________________________________________________________________
actor_rnn (GRU)              (None, 10)                840       
_________________________________________________________________
actor_dense_1 (Dense)        (None, 50)                550       
_________________________________________________________________
batch_normalization (BatchNo (None, 50)                200       
_________________________________________________________________
activation (Activation)      (None, 50)                0         
_________________________________________________________________
actor_dense_2 (Dense)        (None, 40)                2040      
_________________________________________________________________
batch_normalization_1 (Batch (None, 40)                160       
_________________________________________________________________
activation_1 (Activation)    (None, 40)                0         
_________________________________________________________________
actor_dense_3 (Dense)        (None, 1)                 41        
_________________________________________________________________
tf_op_layer_actions_scaling  [(None, 1)]               0         
=================================================================
Total params: 3,911
Trainable params: 3,731
Non-trainable params: 180
_________________________________________________________________
None
Model: "critic_network"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
critic_input_state (InputLayer) [(None, 10, 2)]      0                                            
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 9, 16)        80          critic_input_state[0][0]         
__________________________________________________________________________________________________
gru (GRU)                       (None, 10)           840         conv1d_2[0][0]                   
__________________________________________________________________________________________________
critic_dense_1 (Dense)          (None, 50)           550         gru[0][0]                        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 50)           200         critic_dense_1[0][0]             
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
critic_input_action (InputLayer [(None, 1)]          0                                            
__________________________________________________________________________________________________
critic_dense_2_state (Dense)    (None, 20)           1020        activation_4[0][0]               
__________________________________________________________________________________________________
critic_dense_2_action (Dense)   (None, 20)           40          critic_input_action[0][0]        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 40)           0           critic_dense_2_state[0][0]       
                                                                 critic_dense_2_action[0][0]      
__________________________________________________________________________________________________
critic_dense_3_state (Dense)    (None, 20)           820         concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20)           80          critic_dense_3_state[0][0]       
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20)           0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
Q_val (Dense)                   (None, 1)            21          activation_5[0][0]               
==================================================================================================
Total params: 3,651
Trainable params: 3,511
Non-trainable params: 140
__________________________________________________________________________________________________
None
starting the simulation
running - train_rnn_cbf
| Reward: 11261.3729 | Episode: 0 | Qmax: 9.8824
| Reward: 11261.3727 | Episode: 1 | Qmax: 19.3551
| Reward: 11261.3728 | Episode: 2 | Qmax: 29.2931
| Reward: 11261.3728 | Episode: 3 | Qmax: 42.2147
| Reward: 11261.3728 | Episode: 4 | Qmax: 55.5461
| Reward: 11261.3728 | Episode: 5 | Qmax: 68.4885
| Reward: 11261.3727 | Episode: 6 | Qmax: 81.2192
| Reward: 11261.3728 | Episode: 7 | Qmax: 94.1627
| Reward: 11261.3727 | Episode: 8 | Qmax: 107.3271
| Reward: 11261.3727 | Episode: 9 | Qmax: 119.8025
| Reward: 11261.3728 | Episode: 10 | Qmax: 131.5735
| Reward: 11261.3728 | Episode: 11 | Qmax: 140.8385
| Reward: 11261.3728 | Episode: 12 | Qmax: 148.1144
| Reward: 11261.3729 | Episode: 13 | Qmax: 155.3763
| Reward: 11261.3728 | Episode: 14 | Qmax: 161.3374
| Reward: 11261.3729 | Episode: 15 | Qmax: 168.3482
| Reward: 11261.3728 | Episode: 16 | Qmax: 175.8565
| Reward: 11261.3728 | Episode: 17 | Qmax: 182.4078
| Reward: 11261.3728 | Episode: 18 | Qmax: 189.6576
| Reward: 11261.3728 | Episode: 19 | Qmax: 198.7535
| Reward: 11261.3729 | Episode: 20 | Qmax: 209.4919
| Reward: 11261.3728 | Episode: 21 | Qmax: 220.5963
| Reward: 11261.3728 | Episode: 22 | Qmax: 231.7864
| Reward: 11261.3728 | Episode: 23 | Qmax: 242.6979
| Reward: 11261.3728 | Episode: 24 | Qmax: 253.3953
| Reward: 11261.3729 | Episode: 25 | Qmax: 263.2535
| Reward: 11261.3728 | Episode: 26 | Qmax: 272.2850
| Reward: 11261.3728 | Episode: 27 | Qmax: 281.0720
| Reward: 11261.3728 | Episode: 28 | Qmax: 288.8605
| Reward: 11261.3728 | Episode: 29 | Qmax: 296.5188
| Reward: 11261.3727 | Episode: 30 | Qmax: 303.5719
| Reward: 11261.3728 | Episode: 31 | Qmax: 310.5634
| Reward: 11261.3727 | Episode: 32 | Qmax: 317.1577
| Reward: 11261.3728 | Episode: 33 | Qmax: 323.9783
| Reward: 11261.3728 | Episode: 34 | Qmax: 332.0729
| Reward: 11261.3729 | Episode: 35 | Qmax: 339.9288
| Reward: 11261.3727 | Episode: 36 | Qmax: 348.1834
| Reward: 11261.3728 | Episode: 37 | Qmax: 356.4117
| Reward: 11261.3729 | Episode: 38 | Qmax: 362.3814
| Reward: 11261.3727 | Episode: 39 | Qmax: 366.3516
| Reward: 11261.3728 | Episode: 40 | Qmax: 367.9103
| Reward: 11261.3728 | Episode: 41 | Qmax: 368.6941
| Reward: 11261.3728 | Episode: 42 | Qmax: 368.6063
| Reward: 11261.3728 | Episode: 43 | Qmax: 371.9224
| Reward: 11261.3729 | Episode: 44 | Qmax: 392.4969
| Reward: 11261.3728 | Episode: 45 | Qmax: 411.3839
| Reward: 11261.3729 | Episode: 46 | Qmax: 424.9126
| Reward: 11261.3728 | Episode: 47 | Qmax: 428.6087
| Reward: 11261.3728 | Episode: 48 | Qmax: 430.2255
| Reward: 11261.3728 | Episode: 49 | Qmax: 443.3632
| Reward: 11261.3729 | Episode: 50 | Qmax: 464.6298
| Reward: 11261.3728 | Episode: 51 | Qmax: 503.8534
| Reward: 11261.3727 | Episode: 52 | Qmax: 558.4446
| Reward: 11261.3728 | Episode: 53 | Qmax: 623.0310
| Reward: 11261.3728 | Episode: 54 | Qmax: 689.9754
| Reward: 11261.3728 | Episode: 55 | Qmax: 748.4230
| Reward: 11261.3729 | Episode: 56 | Qmax: 813.6266
| Reward: 11261.3728 | Episode: 57 | Qmax: 855.5693
| Reward: 11261.3729 | Episode: 58 | Qmax: 884.8654
| Reward: 11261.3728 | Episode: 59 | Qmax: 911.4670
| Reward: 11261.3728 | Episode: 60 | Qmax: 928.6136
| Reward: 11261.3728 | Episode: 61 | Qmax: 933.6767
| Reward: 11261.3729 | Episode: 62 | Qmax: 933.4596
| Reward: 11261.3728 | Episode: 63 | Qmax: 913.1519
| Reward: 11261.3729 | Episode: 64 | Qmax: 849.5529
| Reward: 11261.3729 | Episode: 65 | Qmax: 799.9492
| Reward: 11261.3729 | Episode: 66 | Qmax: 746.1947
| Reward: 11261.3728 | Episode: 67 | Qmax: 694.3833
| Reward: 11261.3728 | Episode: 68 | Qmax: 662.6434
| Reward: 11261.3728 | Episode: 69 | Qmax: 639.1685
| Reward: 11261.3728 | Episode: 70 | Qmax: 596.1960
| Reward: 11261.3728 | Episode: 71 | Qmax: 566.7065
| Reward: 11261.3728 | Episode: 72 | Qmax: 554.5059
| Reward: 11261.3728 | Episode: 73 | Qmax: 544.0530
| Reward: 11261.3728 | Episode: 74 | Qmax: 526.0723
| Reward: 11261.3728 | Episode: 75 | Qmax: 507.6073
| Reward: 11261.3728 | Episode: 76 | Qmax: 484.7245
| Reward: 11261.3728 | Episode: 77 | Qmax: 468.6580
| Reward: 11261.3728 | Episode: 78 | Qmax: 454.7844
| Reward: 11261.3728 | Episode: 79 | Qmax: 442.8032
| Reward: 11261.3727 | Episode: 80 | Qmax: 430.1117
| Reward: 11261.3728 | Episode: 81 | Qmax: 426.6272
| Reward: 11261.3728 | Episode: 82 | Qmax: 427.8632
| Reward: 11261.3728 | Episode: 83 | Qmax: 433.4418
| Reward: 11261.3728 | Episode: 84 | Qmax: 443.5828
| Reward: 11261.3728 | Episode: 85 | Qmax: 454.6138
| Reward: 11261.3729 | Episode: 86 | Qmax: 466.9365
| Reward: 11261.3728 | Episode: 87 | Qmax: 481.4748
| Reward: 11261.3728 | Episode: 88 | Qmax: 496.0673
| Reward: 11261.3727 | Episode: 89 | Qmax: 511.7049
| Reward: 11261.3727 | Episode: 90 | Qmax: 528.5687
| Reward: 11261.3728 | Episode: 91 | Qmax: 546.6924
| Reward: 11261.3727 | Episode: 92 | Qmax: 564.5496
| Reward: 11261.3728 | Episode: 93 | Qmax: 582.2278
| Reward: 11261.3728 | Episode: 94 | Qmax: 600.4119
| Reward: 11261.3728 | Episode: 95 | Qmax: 617.4820
| Reward: 11261.3727 | Episode: 96 | Qmax: 634.9192
| Reward: 11261.3728 | Episode: 97 | Qmax: 651.6856
| Reward: 11261.3728 | Episode: 98 | Qmax: 668.4529
| Reward: 11261.3729 | Episode: 99 | Qmax: 685.8907
| Reward: 11261.3727 | Episode: 100 | Qmax: 705.8429
| Reward: 11261.3728 | Episode: 101 | Qmax: 726.1474
| Reward: 11261.3728 | Episode: 102 | Qmax: 750.7309
| Reward: 11261.3728 | Episode: 103 | Qmax: 777.9445
| Reward: 11261.3727 | Episode: 104 | Qmax: 808.7740
| Reward: 11261.3729 | Episode: 105 | Qmax: 842.2374
| Reward: 11261.3728 | Episode: 106 | Qmax: 877.2026
| Reward: 11261.3728 | Episode: 107 | Qmax: 914.2836
| Reward: 11261.3728 | Episode: 108 | Qmax: 952.2342
| Reward: 11261.3728 | Episode: 109 | Qmax: 990.4574
| Reward: 11261.3728 | Episode: 110 | Qmax: 1025.9177
| Reward: 11261.3728 | Episode: 111 | Qmax: 1057.2179
| Reward: 11261.3728 | Episode: 112 | Qmax: 1087.6565
| Reward: 11261.3728 | Episode: 113 | Qmax: 1113.8873
| Reward: 11261.3728 | Episode: 114 | Qmax: 1136.3774
| Reward: 11261.3729 | Episode: 115 | Qmax: 1156.0564
| Reward: 11261.3729 | Episode: 116 | Qmax: 1171.2276
| Reward: 11261.3728 | Episode: 117 | Qmax: 1181.4085
| Reward: 11261.3727 | Episode: 118 | Qmax: 1184.8359
| Reward: 11261.3728 | Episode: 119 | Qmax: 1182.0612
| Reward: 11261.3728 | Episode: 120 | Qmax: 1170.1245
| Reward: 11261.3728 | Episode: 121 | Qmax: 1151.8032
| Reward: 11261.3728 | Episode: 122 | Qmax: 1125.5429
| Reward: 11261.3728 | Episode: 123 | Qmax: 1091.2448
| Reward: 11261.3727 | Episode: 124 | Qmax: 1051.1065
| Reward: 11261.3728 | Episode: 125 | Qmax: 1006.2460
| Reward: 11261.3728 | Episode: 126 | Qmax: 954.9275
| Reward: 11261.3727 | Episode: 127 | Qmax: 899.1364
| Reward: 11261.3728 | Episode: 128 | Qmax: 841.3258
| Reward: 11261.3729 | Episode: 129 | Qmax: 784.3203
| Reward: 11261.3728 | Episode: 130 | Qmax: 730.6433
| Reward: 11261.3728 | Episode: 131 | Qmax: 680.6574
| Reward: 11261.3728 | Episode: 132 | Qmax: 636.6834
| Reward: 11261.3728 | Episode: 133 | Qmax: 599.2790
| Reward: 11261.3729 | Episode: 134 | Qmax: 567.6236
| Reward: 11261.3728 | Episode: 135 | Qmax: 542.4494
| Reward: 11261.3727 | Episode: 136 | Qmax: 523.1004
| Reward: 11261.3728 | Episode: 137 | Qmax: 509.3934
| Reward: 11261.3728 | Episode: 138 | Qmax: 501.1297
| Reward: 11261.3728 | Episode: 139 | Qmax: 497.1460
| Reward: 11261.3728 | Episode: 140 | Qmax: 496.2968
| Reward: 11261.3728 | Episode: 141 | Qmax: 496.7330
| Reward: 11261.3729 | Episode: 142 | Qmax: 497.8479
| Reward: 11261.3728 | Episode: 143 | Qmax: 500.0554
| Reward: 11261.3728 | Episode: 144 | Qmax: 503.1482
| Reward: 11261.3728 | Episode: 145 | Qmax: 506.1110
| Reward: 11261.3727 | Episode: 146 | Qmax: 508.6692
| Reward: 11261.3728 | Episode: 147 | Qmax: 509.6131
| Reward: 11261.3727 | Episode: 148 | Qmax: 509.8394
| Reward: 11261.3728 | Episode: 149 | Qmax: 508.1164
| Reward: 11261.3728 | Episode: 150 | Qmax: 506.1889
| Reward: 11261.3728 | Episode: 151 | Qmax: 504.0925
| Reward: 11261.3728 | Episode: 152 | Qmax: 501.5136
| Reward: 11261.3729 | Episode: 153 | Qmax: 499.5781
| Reward: 11261.3729 | Episode: 154 | Qmax: 499.8190
| Reward: 11261.3729 | Episode: 155 | Qmax: 501.8776
| Reward: 11261.3728 | Episode: 156 | Qmax: 505.3899
| Reward: 11261.3728 | Episode: 157 | Qmax: 509.3101
| Reward: 11261.3728 | Episode: 158 | Qmax: 514.0163
| Reward: 11261.3728 | Episode: 159 | Qmax: 519.7214
| Reward: 11261.3728 | Episode: 160 | Qmax: 525.3457
| Reward: 11261.3729 | Episode: 161 | Qmax: 530.6013
| Reward: 11261.3728 | Episode: 162 | Qmax: 535.9490
| Reward: 11261.3727 | Episode: 163 | Qmax: 540.7120
| Reward: 11261.3728 | Episode: 164 | Qmax: 545.2231
| Reward: 11261.3728 | Episode: 165 | Qmax: 549.2480
| Reward: 11261.3728 | Episode: 166 | Qmax: 553.0808
| Reward: 11261.3728 | Episode: 167 | Qmax: 556.9678
| Reward: 11261.3728 | Episode: 168 | Qmax: 559.8102
| Reward: 11261.3728 | Episode: 169 | Qmax: 561.7712
| Reward: 11261.3728 | Episode: 170 | Qmax: 562.8988
| Reward: 11261.3728 | Episode: 171 | Qmax: 562.9461
| Reward: 11261.3728 | Episode: 172 | Qmax: 562.5638
| Reward: 11261.3728 | Episode: 173 | Qmax: 561.6027
| Reward: 11261.3728 | Episode: 174 | Qmax: 560.6401
| Reward: 11261.3727 | Episode: 175 | Qmax: 560.2463
| Reward: 11261.3728 | Episode: 176 | Qmax: 560.5720
| Reward: 11261.3729 | Episode: 177 | Qmax: 562.1072
| Reward: 11261.3728 | Episode: 178 | Qmax: 564.6591
| Reward: 11261.3728 | Episode: 179 | Qmax: 567.9999
| Reward: 11261.3728 | Episode: 180 | Qmax: 571.6489
| Reward: 11261.3728 | Episode: 181 | Qmax: 575.6874
| Reward: 11261.3728 | Episode: 182 | Qmax: 580.2205
| Reward: 11261.3729 | Episode: 183 | Qmax: 584.8429
| Reward: 11261.3728 | Episode: 184 | Qmax: 589.6962
| Reward: 11261.3727 | Episode: 185 | Qmax: 594.8493
| Reward: 11261.3728 | Episode: 186 | Qmax: 600.1925
| Reward: 11261.3728 | Episode: 187 | Qmax: 605.8034
| Reward: 11261.3729 | Episode: 188 | Qmax: 611.4551
| Reward: 11261.3728 | Episode: 189 | Qmax: 617.6868
| Reward: 11261.3728 | Episode: 190 | Qmax: 623.6333
| Reward: 11261.3729 | Episode: 191 | Qmax: 629.2643
| Reward: 11261.3727 | Episode: 192 | Qmax: 635.1659
| Reward: 11261.3728 | Episode: 193 | Qmax: 640.9253
| Reward: 11261.3728 | Episode: 194 | Qmax: 647.0692
| Reward: 11261.3728 | Episode: 195 | Qmax: 653.6834
| Reward: 11261.3728 | Episode: 196 | Qmax: 659.3778
| Reward: 11261.3729 | Episode: 197 | Qmax: 665.1614
| Reward: 11261.3728 | Episode: 198 | Qmax: 670.7381
| Reward: 11261.3728 | Episode: 199 | Qmax: 676.0213
saving weights
Plotting an new testing environment
