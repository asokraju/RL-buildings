summary_dir /afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=9
use_gpu True
save_model True
load_model False
random_seed 1754
buffer_size 1000000
max_episodes 200
max_episode_len 1464
mini_batch_size 300
actor_lr 0.0001
critic_lr 0.001
gamma 0.99
noise_var 0.0925
scaling True
state_dim 2
action_dim 1
action_bound [1.]
discretization_time 0.001
T_set_max_min [23.0, 26.0]
T_max_min [22.0, 25.0]
time_steps 9
actor_rnn 10
actor_l1 50
actor_l2 40
critic_rnn 10
critic_l1 50
critic_l2 20
tau 0.001
{'T_max_min': [22.0, 25.0],
 'T_set_max_min': [23.0, 26.0],
 'action_bound': array([1.], dtype=float32),
 'action_dim': 1,
 'actor_l1': 50,
 'actor_l2': 40,
 'actor_lr': 0.0001,
 'actor_rnn': 10,
 'buffer_size': 1000000,
 'critic_l1': 50,
 'critic_l2': 20,
 'critic_lr': 0.001,
 'critic_rnn': 10,
 'discretization_time': 0.001,
 'gamma': 0.99,
 'load_model': False,
 'max_episode_len': 1464,
 'max_episodes': 200,
 'mini_batch_size': 300,
 'noise_var': 0.0925,
 'random_seed': 1754,
 'save_model': True,
 'scaling': True,
 'state_dim': 2,
 'summary_dir': '/afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=9',
 'tau': 0.001,
 'time_steps': 9,
 'use_gpu': True}
starting the scaling
finished the scaling
[0.47926085 0.02820973] [ 24.00870657 -28.55468736]
initalizing the actor and critic func
loading the weights
Model: "actor_network"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
actor_input_state (InputLaye [(None, 9, 2)]            0         
_________________________________________________________________
conv1d (Conv1D)              (None, 8, 16)             80        
_________________________________________________________________
actor_rnn (GRU)              (None, 10)                840       
_________________________________________________________________
actor_dense_1 (Dense)        (None, 50)                550       
_________________________________________________________________
batch_normalization (BatchNo (None, 50)                200       
_________________________________________________________________
activation (Activation)      (None, 50)                0         
_________________________________________________________________
actor_dense_2 (Dense)        (None, 40)                2040      
_________________________________________________________________
batch_normalization_1 (Batch (None, 40)                160       
_________________________________________________________________
activation_1 (Activation)    (None, 40)                0         
_________________________________________________________________
actor_dense_3 (Dense)        (None, 1)                 41        
_________________________________________________________________
tf_op_layer_actions_scaling  [(None, 1)]               0         
=================================================================
Total params: 3,911
Trainable params: 3,731
Non-trainable params: 180
_________________________________________________________________
None
Model: "critic_network"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
critic_input_state (InputLayer) [(None, 9, 2)]       0                                            
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 8, 16)        80          critic_input_state[0][0]         
__________________________________________________________________________________________________
gru (GRU)                       (None, 10)           840         conv1d_2[0][0]                   
__________________________________________________________________________________________________
critic_dense_1 (Dense)          (None, 50)           550         gru[0][0]                        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 50)           200         critic_dense_1[0][0]             
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
critic_input_action (InputLayer [(None, 1)]          0                                            
__________________________________________________________________________________________________
critic_dense_2_state (Dense)    (None, 20)           1020        activation_4[0][0]               
__________________________________________________________________________________________________
critic_dense_2_action (Dense)   (None, 20)           40          critic_input_action[0][0]        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 40)           0           critic_dense_2_state[0][0]       
                                                                 critic_dense_2_action[0][0]      
__________________________________________________________________________________________________
critic_dense_3_state (Dense)    (None, 20)           820         concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20)           80          critic_dense_3_state[0][0]       
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20)           0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
Q_val (Dense)                   (None, 1)            21          activation_5[0][0]               
==================================================================================================
Total params: 3,651
Trainable params: 3,511
Non-trainable params: 140
__________________________________________________________________________________________________
None
starting the simulation
running - train_rnn_cbf
| Reward: 10051.9018 | Episode: 0 | Qmax: 9.4661
| Reward: 9840.7974 | Episode: 1 | Qmax: 18.8335
| Reward: 9840.3336 | Episode: 2 | Qmax: 29.2083
| Reward: 9840.6381 | Episode: 3 | Qmax: 42.2059
| Reward: 9840.4957 | Episode: 4 | Qmax: 56.8208
| Reward: 10620.6142 | Episode: 5 | Qmax: 71.9707
| Reward: 11231.0570 | Episode: 6 | Qmax: 88.6875
| Reward: 11230.7951 | Episode: 7 | Qmax: 108.0749
| Reward: 11230.7534 | Episode: 8 | Qmax: 128.3033
| Reward: 11231.1124 | Episode: 9 | Qmax: 149.2338
| Reward: 11231.2795 | Episode: 10 | Qmax: 170.7115
| Reward: 11231.0345 | Episode: 11 | Qmax: 191.6034
| Reward: 11230.8686 | Episode: 12 | Qmax: 211.9277
| Reward: 11230.4878 | Episode: 13 | Qmax: 229.4047
| Reward: 11231.3111 | Episode: 14 | Qmax: 244.4913
| Reward: 11231.3579 | Episode: 15 | Qmax: 258.8546
| Reward: 11230.4547 | Episode: 16 | Qmax: 272.7743
| Reward: 11230.8167 | Episode: 17 | Qmax: 287.8144
| Reward: 11230.9049 | Episode: 18 | Qmax: 304.3897
| Reward: 11231.1380 | Episode: 19 | Qmax: 321.6956
| Reward: 11231.2798 | Episode: 20 | Qmax: 339.0249
| Reward: 11231.2446 | Episode: 21 | Qmax: 356.2730
| Reward: 11231.4904 | Episode: 22 | Qmax: 372.6070
| Reward: 11230.8030 | Episode: 23 | Qmax: 388.3363
| Reward: 11230.7950 | Episode: 24 | Qmax: 402.9725
| Reward: 11230.6526 | Episode: 25 | Qmax: 416.6618
| Reward: 11230.7728 | Episode: 26 | Qmax: 429.1953
| Reward: 11231.4833 | Episode: 27 | Qmax: 441.0860
| Reward: 11230.7973 | Episode: 28 | Qmax: 452.8643
| Reward: 11230.9324 | Episode: 29 | Qmax: 464.8083
| Reward: 11230.2349 | Episode: 30 | Qmax: 477.0435
| Reward: 11230.8172 | Episode: 31 | Qmax: 489.1541
| Reward: 11230.9007 | Episode: 32 | Qmax: 501.3700
| Reward: 11231.0259 | Episode: 33 | Qmax: 513.2871
| Reward: 11230.7096 | Episode: 34 | Qmax: 524.9884
| Reward: 11231.2899 | Episode: 35 | Qmax: 536.8537
| Reward: 11231.4161 | Episode: 36 | Qmax: 548.2153
| Reward: 11231.2486 | Episode: 37 | Qmax: 559.6346
| Reward: 11230.9000 | Episode: 38 | Qmax: 570.7024
| Reward: 11230.9900 | Episode: 39 | Qmax: 582.3659
| Reward: 11230.5045 | Episode: 40 | Qmax: 593.8373
| Reward: 11230.8059 | Episode: 41 | Qmax: 605.6391
| Reward: 11230.9154 | Episode: 42 | Qmax: 617.4426
| Reward: 11230.8968 | Episode: 43 | Qmax: 629.3591
| Reward: 11230.6188 | Episode: 44 | Qmax: 641.3616
| Reward: 11230.5166 | Episode: 45 | Qmax: 653.2186
| Reward: 11231.0942 | Episode: 46 | Qmax: 664.9094
| Reward: 11230.5003 | Episode: 47 | Qmax: 676.0725
| Reward: 11230.5884 | Episode: 48 | Qmax: 687.3651
| Reward: 11231.0915 | Episode: 49 | Qmax: 698.1447
| Reward: 11230.8090 | Episode: 50 | Qmax: 708.5613
| Reward: 11230.6178 | Episode: 51 | Qmax: 718.9350
| Reward: 11230.8181 | Episode: 52 | Qmax: 729.6283
| Reward: 11231.4319 | Episode: 53 | Qmax: 740.4469
| Reward: 11230.8790 | Episode: 54 | Qmax: 751.3739
| Reward: 11230.3354 | Episode: 55 | Qmax: 762.6783
| Reward: 11230.9377 | Episode: 56 | Qmax: 774.0156
| Reward: 11230.6985 | Episode: 57 | Qmax: 785.4262
| Reward: 11230.7554 | Episode: 58 | Qmax: 797.1111
| Reward: 11230.8172 | Episode: 59 | Qmax: 809.4091
| Reward: 11230.9169 | Episode: 60 | Qmax: 821.1853
| Reward: 11230.9036 | Episode: 61 | Qmax: 833.0750
| Reward: 11231.0030 | Episode: 62 | Qmax: 845.1929
| Reward: 11230.8388 | Episode: 63 | Qmax: 856.9547
| Reward: 11230.8311 | Episode: 64 | Qmax: 868.5178
| Reward: 11230.6838 | Episode: 65 | Qmax: 880.1069
| Reward: 11230.9785 | Episode: 66 | Qmax: 890.1465
| Reward: 11231.1736 | Episode: 67 | Qmax: 901.1214
| Reward: 11230.7678 | Episode: 68 | Qmax: 911.5553
| Reward: 11230.8684 | Episode: 69 | Qmax: 921.8708
| Reward: 11231.1361 | Episode: 70 | Qmax: 931.7826
| Reward: 11230.5875 | Episode: 71 | Qmax: 941.7550
| Reward: 11230.5437 | Episode: 72 | Qmax: 951.5755
| Reward: 11230.6260 | Episode: 73 | Qmax: 961.1901
| Reward: 11230.5812 | Episode: 74 | Qmax: 971.3977
| Reward: 11230.7496 | Episode: 75 | Qmax: 982.3937
| Reward: 11230.6411 | Episode: 76 | Qmax: 993.9080
| Reward: 11231.1112 | Episode: 77 | Qmax: 1005.4578
| Reward: 11231.2442 | Episode: 78 | Qmax: 1016.6847
| Reward: 11231.0500 | Episode: 79 | Qmax: 1027.8523
| Reward: 11230.6485 | Episode: 80 | Qmax: 1038.7405
| Reward: 11231.3383 | Episode: 81 | Qmax: 1049.4040
| Reward: 11231.1202 | Episode: 82 | Qmax: 1059.9272
| Reward: 11230.5434 | Episode: 83 | Qmax: 1071.0851
| Reward: 11230.9965 | Episode: 84 | Qmax: 1083.0276
| Reward: 11230.8904 | Episode: 85 | Qmax: 1096.3251
| Reward: 11230.9664 | Episode: 86 | Qmax: 1110.0828
| Reward: 11231.0199 | Episode: 87 | Qmax: 1126.0759
| Reward: 11231.0236 | Episode: 88 | Qmax: 1139.2734
| Reward: 11230.4234 | Episode: 89 | Qmax: 1151.6252
| Reward: 11230.9061 | Episode: 90 | Qmax: 1163.8144
| Reward: 11230.7945 | Episode: 91 | Qmax: 1174.2752
| Reward: 11230.9164 | Episode: 92 | Qmax: 1186.0136
| Reward: 11231.1363 | Episode: 93 | Qmax: 1197.0221
| Reward: 11230.5692 | Episode: 94 | Qmax: 1210.1876
| Reward: 11230.2344 | Episode: 95 | Qmax: 1224.2198
| Reward: 11230.6607 | Episode: 96 | Qmax: 1239.0558
| Reward: 11230.9745 | Episode: 97 | Qmax: 1254.3748
| Reward: 11230.7606 | Episode: 98 | Qmax: 1270.4837
| Reward: 11230.4460 | Episode: 99 | Qmax: 1286.3693
| Reward: 11230.6259 | Episode: 100 | Qmax: 1301.1802
| Reward: 11231.1246 | Episode: 101 | Qmax: 1317.0149
| Reward: 11231.0819 | Episode: 102 | Qmax: 1327.9989
| Reward: 11230.4268 | Episode: 103 | Qmax: 1339.8605
| Reward: 11231.1041 | Episode: 104 | Qmax: 1350.5714
| Reward: 11231.0314 | Episode: 105 | Qmax: 1357.2820
| Reward: 11230.9752 | Episode: 106 | Qmax: 1359.3628
| Reward: 11230.5361 | Episode: 107 | Qmax: 1364.4773
| Reward: 11230.7876 | Episode: 108 | Qmax: 1365.6366
| Reward: 11230.7859 | Episode: 109 | Qmax: 1369.8430
| Reward: 11231.1345 | Episode: 110 | Qmax: 1370.8517
| Reward: 11231.0344 | Episode: 111 | Qmax: 1374.7666
| Reward: 11230.5560 | Episode: 112 | Qmax: 1375.1237
| Reward: 11230.5534 | Episode: 113 | Qmax: 1380.3285
| Reward: 11231.3375 | Episode: 114 | Qmax: 1388.3761
| Reward: 11231.0221 | Episode: 115 | Qmax: 1396.6783
| Reward: 11230.7600 | Episode: 116 | Qmax: 1405.7572
| Reward: 11231.1825 | Episode: 117 | Qmax: 1420.5973
| Reward: 11231.3427 | Episode: 118 | Qmax: 1431.6951
| Reward: 11231.0432 | Episode: 119 | Qmax: 1448.7627
| Reward: 11230.9388 | Episode: 120 | Qmax: 1465.5325
| Reward: 11230.9811 | Episode: 121 | Qmax: 1488.6878
| Reward: 11230.9015 | Episode: 122 | Qmax: 1505.0684
| Reward: 11231.2771 | Episode: 123 | Qmax: 1521.3941
| Reward: 11231.2400 | Episode: 124 | Qmax: 1532.4864
| Reward: 11231.2131 | Episode: 125 | Qmax: 1539.5903
| Reward: 11230.4640 | Episode: 126 | Qmax: 1548.4353
| Reward: 11231.0877 | Episode: 127 | Qmax: 1559.0337
| Reward: 11230.8189 | Episode: 128 | Qmax: 1556.3953
| Reward: 11230.9060 | Episode: 129 | Qmax: 1561.7464
| Reward: 11231.7537 | Episode: 130 | Qmax: 1574.7666
| Reward: 11231.4589 | Episode: 131 | Qmax: 1574.0113
| Reward: 11230.9078 | Episode: 132 | Qmax: 1568.0513
| Reward: 11230.9581 | Episode: 133 | Qmax: 1563.4253
| Reward: 11231.4640 | Episode: 134 | Qmax: 1565.4480
| Reward: 11231.2447 | Episode: 135 | Qmax: 1566.5782
| Reward: 11231.1736 | Episode: 136 | Qmax: 1568.7404
| Reward: 11231.0765 | Episode: 137 | Qmax: 1571.7110
| Reward: 11230.7239 | Episode: 138 | Qmax: 1571.7589
| Reward: 11231.5113 | Episode: 139 | Qmax: 1577.7372
| Reward: 11231.2958 | Episode: 140 | Qmax: 1583.3430
| Reward: 11230.4241 | Episode: 141 | Qmax: 1594.9167
| Reward: 11230.8457 | Episode: 142 | Qmax: 1607.7293
| Reward: 11230.6584 | Episode: 143 | Qmax: 1621.0832
| Reward: 11230.7990 | Episode: 144 | Qmax: 1633.4180
| Reward: 11230.8855 | Episode: 145 | Qmax: 1640.0831
| Reward: 11230.8876 | Episode: 146 | Qmax: 1644.7824
| Reward: 11230.5483 | Episode: 147 | Qmax: 1641.7266
| Reward: 11231.3020 | Episode: 148 | Qmax: 1640.1884
| Reward: 11230.6590 | Episode: 149 | Qmax: 1639.9744
| Reward: 11230.8768 | Episode: 150 | Qmax: 1638.2149
| Reward: 11230.5082 | Episode: 151 | Qmax: 1637.1060
| Reward: 11230.7303 | Episode: 152 | Qmax: 1634.6560
| Reward: 11231.2823 | Episode: 153 | Qmax: 1633.5899
| Reward: 11230.6396 | Episode: 154 | Qmax: 1633.2262
| Reward: 11230.6998 | Episode: 155 | Qmax: 1629.2537
| Reward: 11231.5622 | Episode: 156 | Qmax: 1629.5286
| Reward: 11230.6609 | Episode: 157 | Qmax: 1626.8326
| Reward: 11230.7951 | Episode: 158 | Qmax: 1621.2930
| Reward: 11230.5491 | Episode: 159 | Qmax: 1618.8303
| Reward: 11231.0608 | Episode: 160 | Qmax: 1614.7735
| Reward: 11230.6888 | Episode: 161 | Qmax: 1613.2431
| Reward: 11231.0552 | Episode: 162 | Qmax: 1611.7621
| Reward: 11231.1059 | Episode: 163 | Qmax: 1618.5221
| Reward: 11231.0568 | Episode: 164 | Qmax: 1618.3170
| Reward: 11230.9700 | Episode: 165 | Qmax: 1620.8505
| Reward: 11230.9233 | Episode: 166 | Qmax: 1635.6706
| Reward: 11230.7520 | Episode: 167 | Qmax: 1629.9026
| Reward: 11231.4245 | Episode: 168 | Qmax: 1623.2696
| Reward: 11230.8484 | Episode: 169 | Qmax: 1623.8505
| Reward: 11230.9707 | Episode: 170 | Qmax: 1619.3873
| Reward: 11230.7243 | Episode: 171 | Qmax: 1617.8595
| Reward: 11231.8144 | Episode: 172 | Qmax: 1615.9884
| Reward: 11230.4550 | Episode: 173 | Qmax: 1620.1034
| Reward: 11230.9257 | Episode: 174 | Qmax: 1627.3006
| Reward: 11230.2377 | Episode: 175 | Qmax: 1633.8272
| Reward: 11231.0419 | Episode: 176 | Qmax: 1636.8029
| Reward: 11230.4221 | Episode: 177 | Qmax: 1635.7208
| Reward: 11231.5061 | Episode: 178 | Qmax: 1623.5537
| Reward: 11230.8311 | Episode: 179 | Qmax: 1614.1075
| Reward: 11230.8485 | Episode: 180 | Qmax: 1615.2314
| Reward: 11231.4341 | Episode: 181 | Qmax: 1619.0715
| Reward: 11231.1906 | Episode: 182 | Qmax: 1621.6617
| Reward: 11230.8517 | Episode: 183 | Qmax: 1633.5542
| Reward: 11230.7803 | Episode: 184 | Qmax: 1652.4989
| Reward: 11230.7167 | Episode: 185 | Qmax: 1669.4148
| Reward: 11231.2054 | Episode: 186 | Qmax: 1691.1577
| Reward: 11230.4961 | Episode: 187 | Qmax: 1714.2656
| Reward: 11230.7279 | Episode: 188 | Qmax: 1741.6650
| Reward: 11230.8038 | Episode: 189 | Qmax: 1768.9340
| Reward: 11230.7270 | Episode: 190 | Qmax: 1800.0762
| Reward: 11230.8155 | Episode: 191 | Qmax: 1828.7983
| Reward: 11231.3379 | Episode: 192 | Qmax: 1865.5879
| Reward: 11231.8761 | Episode: 193 | Qmax: 1919.1527
| Reward: 11231.1811 | Episode: 194 | Qmax: 1988.9264
| Reward: 11230.7581 | Episode: 195 | Qmax: 2078.0182
| Reward: 11231.2142 | Episode: 196 | Qmax: 2189.3328
| Reward: 11231.5850 | Episode: 197 | Qmax: 2353.3837
| Reward: 11230.6217 | Episode: 198 | Qmax: 2532.3334
| Reward: 11230.8013 | Episode: 199 | Qmax: 2721.0966
saving weights
Plotting an new testing environment
