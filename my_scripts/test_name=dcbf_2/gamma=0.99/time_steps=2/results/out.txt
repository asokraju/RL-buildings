summary_dir /afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=2
use_gpu True
save_model True
load_model False
random_seed 1754
buffer_size 1000000
max_episodes 200
max_episode_len 1464
mini_batch_size 300
actor_lr 0.0001
critic_lr 0.001
gamma 0.99
noise_var 0.0925
scaling True
state_dim 2
action_dim 1
action_bound [1.]
discretization_time 0.001
T_set_max_min [23.0, 26.0]
T_max_min [22.0, 25.0]
time_steps 2
actor_rnn 10
actor_l1 50
actor_l2 40
critic_rnn 10
critic_l1 50
critic_l2 20
tau 0.001
{'T_max_min': [22.0, 25.0],
 'T_set_max_min': [23.0, 26.0],
 'action_bound': array([1.], dtype=float32),
 'action_dim': 1,
 'actor_l1': 50,
 'actor_l2': 40,
 'actor_lr': 0.0001,
 'actor_rnn': 10,
 'buffer_size': 1000000,
 'critic_l1': 50,
 'critic_l2': 20,
 'critic_lr': 0.001,
 'critic_rnn': 10,
 'discretization_time': 0.001,
 'gamma': 0.99,
 'load_model': False,
 'max_episode_len': 1464,
 'max_episodes': 200,
 'mini_batch_size': 300,
 'noise_var': 0.0925,
 'random_seed': 1754,
 'save_model': True,
 'scaling': True,
 'state_dim': 2,
 'summary_dir': '/afs/crc.nd.edu/user/k/kkosaraj/GITHUB_BUILD_1/my_scripts/test_name=dcbf_2/gamma=0.99/time_steps=2',
 'tau': 0.001,
 'time_steps': 2,
 'use_gpu': True}
starting the scaling
finished the scaling
[0.48475327 0.02816104] [ 24.00169879 -28.56691985]
initalizing the actor and critic func
loading the weights
Model: "actor_network"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
actor_input_state (InputLaye [(None, 2, 2)]            0         
_________________________________________________________________
conv1d (Conv1D)              (None, 1, 16)             80        
_________________________________________________________________
actor_rnn (GRU)              (None, 10)                840       
_________________________________________________________________
actor_dense_1 (Dense)        (None, 50)                550       
_________________________________________________________________
batch_normalization (BatchNo (None, 50)                200       
_________________________________________________________________
activation (Activation)      (None, 50)                0         
_________________________________________________________________
actor_dense_2 (Dense)        (None, 40)                2040      
_________________________________________________________________
batch_normalization_1 (Batch (None, 40)                160       
_________________________________________________________________
activation_1 (Activation)    (None, 40)                0         
_________________________________________________________________
actor_dense_3 (Dense)        (None, 1)                 41        
_________________________________________________________________
tf_op_layer_actions_scaling  [(None, 1)]               0         
=================================================================
Total params: 3,911
Trainable params: 3,731
Non-trainable params: 180
_________________________________________________________________
None
Model: "critic_network"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
critic_input_state (InputLayer) [(None, 2, 2)]       0                                            
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 1, 16)        80          critic_input_state[0][0]         
__________________________________________________________________________________________________
gru (GRU)                       (None, 10)           840         conv1d_2[0][0]                   
__________________________________________________________________________________________________
critic_dense_1 (Dense)          (None, 50)           550         gru[0][0]                        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 50)           200         critic_dense_1[0][0]             
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
critic_input_action (InputLayer [(None, 1)]          0                                            
__________________________________________________________________________________________________
critic_dense_2_state (Dense)    (None, 20)           1020        activation_4[0][0]               
__________________________________________________________________________________________________
critic_dense_2_action (Dense)   (None, 20)           40          critic_input_action[0][0]        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 40)           0           critic_dense_2_state[0][0]       
                                                                 critic_dense_2_action[0][0]      
__________________________________________________________________________________________________
critic_dense_3_state (Dense)    (None, 20)           820         concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20)           80          critic_dense_3_state[0][0]       
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20)           0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
Q_val (Dense)                   (None, 1)            21          activation_5[0][0]               
==================================================================================================
Total params: 3,651
Trainable params: 3,511
Non-trainable params: 140
__________________________________________________________________________________________________
None
starting the simulation
running - train_rnn_cbf
| Reward: 10087.0294 | Episode: 0 | Qmax: 9.5876
| Reward: 9861.4439 | Episode: 1 | Qmax: 17.7903
| Reward: 9861.2298 | Episode: 2 | Qmax: 28.7346
| Reward: 9976.4454 | Episode: 3 | Qmax: 42.1801
| Reward: 11248.4582 | Episode: 4 | Qmax: 59.8951
| Reward: 11258.3712 | Episode: 5 | Qmax: 85.2668
| Reward: 11258.7145 | Episode: 6 | Qmax: 117.7113
| Reward: 11258.7486 | Episode: 7 | Qmax: 155.3759
| Reward: 11258.9583 | Episode: 8 | Qmax: 196.5284
| Reward: 11259.2717 | Episode: 9 | Qmax: 239.2581
| Reward: 11259.4012 | Episode: 10 | Qmax: 282.5213
| Reward: 11259.4064 | Episode: 11 | Qmax: 325.5123
| Reward: 11259.0814 | Episode: 12 | Qmax: 366.8139
| Reward: 11258.8832 | Episode: 13 | Qmax: 406.4891
| Reward: 11259.2104 | Episode: 14 | Qmax: 444.3711
| Reward: 11259.7304 | Episode: 15 | Qmax: 480.4113
| Reward: 11259.0702 | Episode: 16 | Qmax: 514.4764
| Reward: 11258.7991 | Episode: 17 | Qmax: 546.8720
| Reward: 11259.2873 | Episode: 18 | Qmax: 578.0419
| Reward: 11259.3615 | Episode: 19 | Qmax: 607.5601
| Reward: 11258.6898 | Episode: 20 | Qmax: 635.0025
| Reward: 11258.5505 | Episode: 21 | Qmax: 660.8490
| Reward: 11259.0394 | Episode: 22 | Qmax: 685.4872
| Reward: 11258.8441 | Episode: 23 | Qmax: 708.5997
| Reward: 11259.0276 | Episode: 24 | Qmax: 730.1711
| Reward: 11259.5659 | Episode: 25 | Qmax: 750.3629
| Reward: 11259.0252 | Episode: 26 | Qmax: 769.4077
| Reward: 11259.1538 | Episode: 27 | Qmax: 786.4229
| Reward: 11259.2086 | Episode: 28 | Qmax: 802.3460
| Reward: 11259.3166 | Episode: 29 | Qmax: 817.1791
| Reward: 11258.9858 | Episode: 30 | Qmax: 830.5393
| Reward: 11259.3822 | Episode: 31 | Qmax: 842.5560
| Reward: 11258.8269 | Episode: 32 | Qmax: 853.6228
| Reward: 11258.7325 | Episode: 33 | Qmax: 863.6396
| Reward: 11259.4464 | Episode: 34 | Qmax: 872.7722
| Reward: 11259.0478 | Episode: 35 | Qmax: 880.9987
| Reward: 11259.1357 | Episode: 36 | Qmax: 888.7924
| Reward: 11258.8868 | Episode: 37 | Qmax: 896.2327
| Reward: 11259.0232 | Episode: 38 | Qmax: 902.0448
| Reward: 11258.5455 | Episode: 39 | Qmax: 907.3609
| Reward: 11258.6546 | Episode: 40 | Qmax: 912.0897
| Reward: 11258.1860 | Episode: 41 | Qmax: 915.7964
| Reward: 11259.1582 | Episode: 42 | Qmax: 919.1139
| Reward: 11258.9335 | Episode: 43 | Qmax: 921.7686
| Reward: 11259.3410 | Episode: 44 | Qmax: 923.8964
| Reward: 11259.0934 | Episode: 45 | Qmax: 925.5216
| Reward: 11259.2158 | Episode: 46 | Qmax: 926.7451
| Reward: 11258.7144 | Episode: 47 | Qmax: 927.0357
| Reward: 11259.2322 | Episode: 48 | Qmax: 927.4781
| Reward: 11258.8107 | Episode: 49 | Qmax: 927.1731
| Reward: 11258.5751 | Episode: 50 | Qmax: 926.4665
| Reward: 11259.2762 | Episode: 51 | Qmax: 925.1670
| Reward: 11259.2751 | Episode: 52 | Qmax: 924.3579
| Reward: 11258.7265 | Episode: 53 | Qmax: 923.0747
| Reward: 11259.1393 | Episode: 54 | Qmax: 922.1565
| Reward: 11259.6599 | Episode: 55 | Qmax: 920.6822
| Reward: 11259.0179 | Episode: 56 | Qmax: 919.3216
| Reward: 11259.0538 | Episode: 57 | Qmax: 917.9703
| Reward: 11258.8385 | Episode: 58 | Qmax: 916.7811
| Reward: 11258.6635 | Episode: 59 | Qmax: 915.4250
| Reward: 11258.8284 | Episode: 60 | Qmax: 914.1955
| Reward: 11259.2847 | Episode: 61 | Qmax: 913.2112
| Reward: 11259.0606 | Episode: 62 | Qmax: 912.1319
| Reward: 11258.7458 | Episode: 63 | Qmax: 910.9441
| Reward: 11259.0603 | Episode: 64 | Qmax: 910.1870
| Reward: 11259.2063 | Episode: 65 | Qmax: 908.9401
| Reward: 11259.2835 | Episode: 66 | Qmax: 908.3038
| Reward: 11259.0067 | Episode: 67 | Qmax: 907.0747
| Reward: 11258.9746 | Episode: 68 | Qmax: 905.7100
| Reward: 11259.1270 | Episode: 69 | Qmax: 904.6314
| Reward: 11258.8792 | Episode: 70 | Qmax: 902.4296
| Reward: 11258.7178 | Episode: 71 | Qmax: 900.8928
| Reward: 11259.0397 | Episode: 72 | Qmax: 899.1975
| Reward: 11259.2740 | Episode: 73 | Qmax: 898.1213
| Reward: 11259.1004 | Episode: 74 | Qmax: 897.2127
| Reward: 11259.6565 | Episode: 75 | Qmax: 894.6680
| Reward: 11259.2037 | Episode: 76 | Qmax: 892.7670
| Reward: 11258.9220 | Episode: 77 | Qmax: 891.3074
| Reward: 11259.3073 | Episode: 78 | Qmax: 888.5145
| Reward: 11258.9135 | Episode: 79 | Qmax: 886.8905
| Reward: 11258.7835 | Episode: 80 | Qmax: 885.8696
| Reward: 11259.4838 | Episode: 81 | Qmax: 884.6856
| Reward: 11259.1002 | Episode: 82 | Qmax: 883.4322
| Reward: 11259.4671 | Episode: 83 | Qmax: 882.2299
| Reward: 11258.7572 | Episode: 84 | Qmax: 880.7289
| Reward: 11259.1608 | Episode: 85 | Qmax: 879.1165
| Reward: 11259.3366 | Episode: 86 | Qmax: 878.2757
| Reward: 11259.5287 | Episode: 87 | Qmax: 875.9413
| Reward: 11258.3462 | Episode: 88 | Qmax: 874.1859
| Reward: 11258.9727 | Episode: 89 | Qmax: 873.1281
| Reward: 11259.5353 | Episode: 90 | Qmax: 871.6250
| Reward: 11259.2990 | Episode: 91 | Qmax: 870.7198
| Reward: 11259.0784 | Episode: 92 | Qmax: 869.3443
| Reward: 11258.9087 | Episode: 93 | Qmax: 868.7131
| Reward: 11259.0387 | Episode: 94 | Qmax: 867.7421
| Reward: 11259.6421 | Episode: 95 | Qmax: 866.8289
| Reward: 11258.9560 | Episode: 96 | Qmax: 866.4652
| Reward: 11258.7880 | Episode: 97 | Qmax: 863.7401
| Reward: 11258.9555 | Episode: 98 | Qmax: 861.2888
| Reward: 11259.0616 | Episode: 99 | Qmax: 860.6700
| Reward: 11258.8834 | Episode: 100 | Qmax: 860.0856
| Reward: 11258.8057 | Episode: 101 | Qmax: 857.8341
| Reward: 11258.8588 | Episode: 102 | Qmax: 857.2993
| Reward: 11258.5135 | Episode: 103 | Qmax: 857.5729
| Reward: 11258.9225 | Episode: 104 | Qmax: 856.1555
| Reward: 11258.7542 | Episode: 105 | Qmax: 854.8794
| Reward: 11258.5623 | Episode: 106 | Qmax: 852.7668
| Reward: 11258.5885 | Episode: 107 | Qmax: 851.1648
| Reward: 11258.6427 | Episode: 108 | Qmax: 850.4574
| Reward: 11258.8424 | Episode: 109 | Qmax: 850.4576
| Reward: 11259.1247 | Episode: 110 | Qmax: 848.9156
| Reward: 11258.8265 | Episode: 111 | Qmax: 847.7883
| Reward: 11258.9333 | Episode: 112 | Qmax: 846.0259
| Reward: 11259.5185 | Episode: 113 | Qmax: 844.8435
| Reward: 11259.2465 | Episode: 114 | Qmax: 843.1706
| Reward: 11259.3340 | Episode: 115 | Qmax: 842.5241
| Reward: 11259.1409 | Episode: 116 | Qmax: 841.0002
| Reward: 11259.2119 | Episode: 117 | Qmax: 839.7998
| Reward: 11259.3091 | Episode: 118 | Qmax: 838.4919
| Reward: 11259.0689 | Episode: 119 | Qmax: 836.9875
| Reward: 11258.9187 | Episode: 120 | Qmax: 835.5576
| Reward: 11259.4089 | Episode: 121 | Qmax: 835.0316
| Reward: 11258.5188 | Episode: 122 | Qmax: 835.3239
| Reward: 11259.1499 | Episode: 123 | Qmax: 832.4785
| Reward: 11259.0942 | Episode: 124 | Qmax: 832.9674
| Reward: 11259.2386 | Episode: 125 | Qmax: 831.2113
| Reward: 11258.8589 | Episode: 126 | Qmax: 830.2899
| Reward: 11259.2968 | Episode: 127 | Qmax: 829.3895
| Reward: 11259.7058 | Episode: 128 | Qmax: 827.7134
| Reward: 11259.3249 | Episode: 129 | Qmax: 827.2229
| Reward: 11259.1696 | Episode: 130 | Qmax: 826.5014
| Reward: 11259.5064 | Episode: 131 | Qmax: 825.1020
| Reward: 11259.0830 | Episode: 132 | Qmax: 823.2945
| Reward: 11259.0133 | Episode: 133 | Qmax: 822.8417
| Reward: 11259.4282 | Episode: 134 | Qmax: 822.6157
| Reward: 11258.9718 | Episode: 135 | Qmax: 821.6307
| Reward: 11258.7438 | Episode: 136 | Qmax: 820.9254
| Reward: 11259.0023 | Episode: 137 | Qmax: 819.7991
| Reward: 11259.1923 | Episode: 138 | Qmax: 819.7209
| Reward: 11258.8915 | Episode: 139 | Qmax: 819.7335
| Reward: 11258.7313 | Episode: 140 | Qmax: 818.2443
| Reward: 11259.0275 | Episode: 141 | Qmax: 816.7835
| Reward: 11258.5541 | Episode: 142 | Qmax: 816.3413
| Reward: 11259.2222 | Episode: 143 | Qmax: 815.5476
| Reward: 11259.3113 | Episode: 144 | Qmax: 817.1417
| Reward: 11258.7680 | Episode: 145 | Qmax: 808.1328
| Reward: 11259.0601 | Episode: 146 | Qmax: 809.8163
| Reward: 11259.5190 | Episode: 147 | Qmax: 811.0749
| Reward: 11258.9014 | Episode: 148 | Qmax: 810.8535
| Reward: 11258.8388 | Episode: 149 | Qmax: 810.6905
| Reward: 11258.4995 | Episode: 150 | Qmax: 811.0042
| Reward: 11258.8732 | Episode: 151 | Qmax: 810.1537
| Reward: 11259.0727 | Episode: 152 | Qmax: 811.2205
| Reward: 11258.8424 | Episode: 153 | Qmax: 810.4073
| Reward: 11258.9678 | Episode: 154 | Qmax: 810.6742
| Reward: 11259.0545 | Episode: 155 | Qmax: 809.9356
| Reward: 11258.8818 | Episode: 156 | Qmax: 810.5550
| Reward: 11258.6916 | Episode: 157 | Qmax: 809.0985
| Reward: 11259.0122 | Episode: 158 | Qmax: 809.2156
| Reward: 11259.4527 | Episode: 159 | Qmax: 809.0999
| Reward: 11258.7982 | Episode: 160 | Qmax: 808.7386
| Reward: 11259.6059 | Episode: 161 | Qmax: 808.9502
| Reward: 11259.0581 | Episode: 162 | Qmax: 808.3490
| Reward: 11258.8922 | Episode: 163 | Qmax: 808.0864
| Reward: 11258.5179 | Episode: 164 | Qmax: 808.1069
| Reward: 11258.8870 | Episode: 165 | Qmax: 806.9823
| Reward: 11258.9542 | Episode: 166 | Qmax: 807.2609
| Reward: 11258.7597 | Episode: 167 | Qmax: 807.1448
| Reward: 11258.6757 | Episode: 168 | Qmax: 806.2583
| Reward: 11258.7366 | Episode: 169 | Qmax: 806.6604
| Reward: 11258.3626 | Episode: 170 | Qmax: 805.3867
| Reward: 11259.3345 | Episode: 171 | Qmax: 806.6287
| Reward: 11259.5308 | Episode: 172 | Qmax: 805.7397
| Reward: 11259.5668 | Episode: 173 | Qmax: 804.4038
| Reward: 11258.4095 | Episode: 174 | Qmax: 805.4239
| Reward: 11258.7907 | Episode: 175 | Qmax: 805.7566
| Reward: 11258.9523 | Episode: 176 | Qmax: 806.4385
| Reward: 11258.5761 | Episode: 177 | Qmax: 805.4456
| Reward: 11259.1850 | Episode: 178 | Qmax: 805.2991
| Reward: 11258.8290 | Episode: 179 | Qmax: 804.5383
| Reward: 11258.4795 | Episode: 180 | Qmax: 803.1605
| Reward: 11258.3144 | Episode: 181 | Qmax: 803.2435
| Reward: 11259.4400 | Episode: 182 | Qmax: 803.2685
| Reward: 11258.8725 | Episode: 183 | Qmax: 803.2417
| Reward: 11258.8053 | Episode: 184 | Qmax: 804.4798
| Reward: 11259.0522 | Episode: 185 | Qmax: 803.9193
| Reward: 11258.8235 | Episode: 186 | Qmax: 804.0405
| Reward: 11259.2809 | Episode: 187 | Qmax: 803.5228
| Reward: 11258.9725 | Episode: 188 | Qmax: 804.2006
| Reward: 11259.4338 | Episode: 189 | Qmax: 805.1093
| Reward: 11258.8386 | Episode: 190 | Qmax: 802.6133
| Reward: 11259.3401 | Episode: 191 | Qmax: 803.8831
| Reward: 11259.1751 | Episode: 192 | Qmax: 803.4927
| Reward: 11259.1941 | Episode: 193 | Qmax: 801.8922
| Reward: 11258.6235 | Episode: 194 | Qmax: 802.2698
| Reward: 11259.1361 | Episode: 195 | Qmax: 803.8535
| Reward: 11259.0467 | Episode: 196 | Qmax: 801.8586
| Reward: 11258.9331 | Episode: 197 | Qmax: 803.2455
| Reward: 11258.9844 | Episode: 198 | Qmax: 802.1650
| Reward: 11258.8949 | Episode: 199 | Qmax: 803.0625
saving weights
Plotting an new testing environment
